{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be95967e",
   "metadata": {
    "id": "L5dnO5Fkd_Lq"
   },
   "source": [
    "Code references:  \n",
    "[1] Joshi, P. (2020). Transfer Learning for NLP: Fine-Tuning BERT for Text Classification. https://www.analyticsvidhya.com/blog/2020/07/transfer-learning-for-nlp-fine-tuning-bert-for-text-classification/  \n",
    "[2] Tran, C. (2021) Tutorial: Fine tuning BERT for Sentiment Analysis. https://skimai.com/fine-tuning-bert-for-sentiment-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3154f0",
   "metadata": {
    "id": "1105eacc"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4b7e55",
   "metadata": {
    "id": "49861711"
   },
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3449a8c3",
   "metadata": {
    "executionInfo": {
     "elapsed": 5055,
     "status": "ok",
     "timestamp": 1630486125855,
     "user": {
      "displayName": "Margaux Bout",
      "photoUrl": "",
      "userId": "14441531522132495975"
     },
     "user_tz": -120
    },
    "id": "ee29dc9e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "from hyperopt import tpe, fmin, STATUS_OK, Trials\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.metrics import accuracy_score\n",
    "import fine_tuning_functions\n",
    "import model_tokenizer_loaders\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19706c",
   "metadata": {
    "id": "6bcd56ca"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7566f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data_nl_english_french_23300\", 'rb') as f:\n",
    "    data_english_french_nl = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcead1a",
   "metadata": {},
   "source": [
    "## Define model to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b7c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_ = \"RobBERT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46874566",
   "metadata": {
    "id": "add55ed8"
   },
   "source": [
    "## Split dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ded906",
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1630486202567,
     "user": {
      "displayName": "Margaux Bout",
      "photoUrl": "",
      "userId": "14441531522132495975"
     },
     "user_tz": -120
    },
    "id": "3ad7974e"
   },
   "outputs": [],
   "source": [
    "train_text, train_labels, val_text, val_labels, test_text, test_labels = fine_tuning_functions.split_dataset(data_english_french_nl, model_name_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0b85c",
   "metadata": {},
   "source": [
    "## Choose model to fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caf6a5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "space, nb_trials, model_name = model_tokenizer_loaders.models_hyperparameters(model_name_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c72f078",
   "metadata": {
    "id": "BT81TAgYDKja"
   },
   "source": [
    "## TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e40849",
   "metadata": {
    "id": "xylmme7_j0f3"
   },
   "outputs": [],
   "source": [
    "def objective_function(params):\n",
    "    \"\"\" Define objective function for TPE algorithm.\n",
    "    The input has to be only the model parameters to be able to work with\n",
    "    the TPE algorithm.\n",
    "    train_text, val_text, test_text, train_labels, val_labels, test_text, \n",
    "    test_labels, model_name has to be defined beforehand.\n",
    "    Returns -accuracy of the model on test set.\n",
    "\n",
    "    Input:\n",
    "    - params: parameters of BERT model and architecture\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the time when the model starts running\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Print selected hyperparameters by TPE\n",
    "    print(params)\n",
    "\n",
    "    # Get the hyperparameters\n",
    "    dropout, epochs, folder_name, lr = params.values()\n",
    "\n",
    "    # Fine-tunes the model with the associated hyperparameters\n",
    "    model = fine_tuning_functions.fine_tuning_model(epochs, lr, dropout, folder_name, train_text, val_text, test_text, train_labels, val_labels, model_name)\n",
    "\n",
    "    # The objective funtion returns -accuracy on test set\n",
    "    # To be able to test, we need the test tensors:\n",
    "    tokenizer = model_tokenizer_loaders.load_tokenizer(model_name)\n",
    "    \n",
    "    #If this is multilingual\n",
    "    if \"test\" in model_name or \"all\" in model_name:\n",
    "        test_seq_nl, test_mask_nl, test_seq_en, test_mask_en, test_seq_fr, test_mask_fr, test_y = fine_tuning_functions.to_tensor_test(tokenizer, test_text, test_labels)\n",
    "    else:\n",
    "        test_seq, test_mask, test_y = fine_tuning_functions.to_tensor_test(tokenizer, test_text, test_labels)\n",
    "\n",
    "    # Load best model just fine-tuned with the previous hyperparameters\n",
    "    path = folder_name + '/saved_weights_lr{:}_dropout{:}_epochs{:}.pt'.format(lr, dropout, epochs)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "\n",
    "    # Compute the accuracy on test set\n",
    "    # The model is too big to be able to predict on the whole test set\n",
    "    # Predict on 500 observations at a time and take the average\n",
    "    # Disctinct two cases: unilingual and multilingual model\n",
    "    \n",
    "    #If this is a multilingual model\n",
    "    if \"test\" in model_name or \"all\" in model_name:\n",
    "        acc_list_nl = []\n",
    "        acc_list_en = []\n",
    "        acc_list_fr = []\n",
    "        for i in range(0, len(test_seq), 500):\n",
    "            with torch.no_grad():\n",
    "                preds_nl = model(test_seq_nl[i:i+500].to(device), test_mask_nl[i:i+500].to(device), model_name)\n",
    "                preds_nl = preds_nl.detach().cpu().numpy()\n",
    "\n",
    "                preds_en = model(test_seq_en[i:i+500].to(device), test_mask_en[i:i+500].to(device), model_name)\n",
    "                preds_en = preds_en.detach().cpu().numpy()\n",
    "\n",
    "                preds_fr = model(test_seq_fr[i:i+500].to(device), test_mask_fr[i:i+500].to(device), model_name)\n",
    "                preds_fr = preds_fr.detach().cpu().numpy()\n",
    "            \n",
    "            # Keep the label number with the highest probability\n",
    "            preds_nl = np.argmax(preds_nl, axis = 1)\n",
    "            preds_en = np.argmax(preds_en, axis = 1)\n",
    "            preds_fr = np.argmax(preds_fr, axis = 1)\n",
    "            \n",
    "            # Add the accuracy of 500 observations to the list\n",
    "            acc_list_nl.append(accuracy_score(test_y[i:i+500], preds_nl))\n",
    "            acc_list_en.append(accuracy_score(test_y[i:i+500], preds_en))\n",
    "            acc_list_fr.append(accuracy_score(test_y[i:i+500], preds_fr))\n",
    "            \n",
    "        acc_nl = sum(acc_list_nl) / len(acc_list_nl)\n",
    "        acc_en = sum(acc_list_en) / len(acc_list_en)\n",
    "        acc_fr = sum(acc_list_fr) / len(acc_list_fr)\n",
    "\n",
    "        acc = (acc_nl + acc_en + acc_fr) / 3\n",
    "                \n",
    "    #If this is an unilingual model\n",
    "    else:\n",
    "        acc_list = []\n",
    "        for i in range(0, len(test_seq), 500):\n",
    "            with torch.no_grad():\n",
    "                preds = model(test_seq[i:i+500].to(device), test_mask[i:i+500].to(device), model_name)\n",
    "                preds = preds.detach().cpu().numpy()\n",
    "            \n",
    "            # Keep the label number with the highest probability\n",
    "            preds = np.argmax(preds, axis = 1)\n",
    "\n",
    "            # Add the accuracy of 500 observations to the list\n",
    "            acc_list.append(accuracy_score(test_y[i:i+500], preds))        \n",
    "\n",
    "        # Take the average to have the complete accuracy\n",
    "        acc = sum(acc_list) / len(acc_list)\n",
    "\n",
    "    print(\"Accuracy:\")\n",
    "    print(acc)\n",
    "    print(\"With one combination of parameters:\")\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    return {\"loss\": -acc, \"status\": STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae75c9",
   "metadata": {
    "id": "J05-sYJ1etMH"
   },
   "source": [
    "## Run TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd0e1d",
   "metadata": {
    "id": "HvHHd8IM5Qsc"
   },
   "outputs": [],
   "source": [
    "# Initialize trials object\n",
    "trials = Trials()\n",
    "\n",
    "# Get time of when TPE algorithm starts\n",
    "start_time = time.time()\n",
    "\n",
    "# Function that run the TPE algorithm with the associated space and number of trials\n",
    "best = fmin(\n",
    "    fn=objective_function,\n",
    "    space = space, \n",
    "    algo=tpe.suggest, \n",
    "    max_evals=nb_trials, \n",
    "    trials=trials,\n",
    "    return_argmin=False\n",
    ")\n",
    "\n",
    "print(\"Total time:\")\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(\"Best: {}\".format(best))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_Mean_clean.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-9.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m74"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
